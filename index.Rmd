---
title: "Prediction Assignment Writeup"
author: 
date: "23 Juni 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project Goal

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.
The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. 

```{r}
library(knitr)
library(caret)
library(rpart)
library(randomForest)
library(rattle)
library(rpart.plot)


```

# Loading data and preprocessing

```{r}
# set the URL for the download
Train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
Test  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

# download the datasets
training <- read.csv(url(Train))
testing  <- read.csv(url(Test))

# create a partition with the training dataset 
inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
TrainSet <- training[inTrain, ]
TestSet  <- training[-inTrain, ]


dim(TrainSet)
dim(TestSet)

# remove variables that are NA
var_na   <- sapply(TrainSet, function(x) mean(is.na(x))) > 0.95
TrainSet <- TrainSet[, var_na==FALSE]
TestSet  <- TestSet[, var_na==FALSE]

# remove identification variables
TrainSet <- TrainSet[, -(1:5)]
TestSet  <- TestSet[, -(1:5)]

# remove variables with near zero variance
nzv <- nearZeroVar(TrainSet)
TrainSet <- TrainSet[, -nzv]
TestSet  <- TestSet[, -nzv]


dim(TrainSet)
dim(TestSet)


```
# Create a Decision Tree

```{r}

modFitDecTree <- train(classe ~ ., data=TrainSet, method="rpart")
print(modFitDecTree$finalModel)
fancyRpartPlot(modFitDecTree$finalModel)

predictDecTree <- predict(modFitDecTree, newdata=TestSet)

confMatDecTree <- confusionMatrix(predictDecTree, TestSet$classe)
confMatDecTree
    
```
###The accuracy is with 0.5854 low.

###We generate now a Gradient boosted Tree model.

# Generating a Gradient Boosted Tree model

```{r}

modFitBoostTree<- train(classe ~ ., method="gbm",data=TrainSet,verbose=FALSE)
print(modFitBoostTree)


predictBoostTree <- predict(modFitBoostTree, newdata=TestSet)

confMatBoostTree <- confusionMatrix(predictBoostTree, TestSet$classe)
confMatBoostTree

```

###The Gradient Boosted Tree model has a better accuracy : 0.9847

# Applying the Gradient Boosted Tree model to the 20 test cases

###The Gradient Boosted Tree model will be applied to the 20 test cases available in the test data: 
```{r}

predictTEST <- predict(modFitBoostTree, newdata=testing)
predictTEST
```
